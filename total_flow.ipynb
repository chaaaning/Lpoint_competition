{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "plt.rcParams[\"figure.figsize\"] = (16,9)\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leechoongsung\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# choongs load\n",
    "df_cust = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_01_DEMO.csv\")\n",
    "df_pdde = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_02_PDDE.csv\")\n",
    "df_cop_u = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_03_COP_U.csv\")\n",
    "df_pd_clac = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_04_PD_CLAC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## osy load\n",
    "# df_cust = pd.read_csv(\"../../LPOINT_BIG_COMP_01_DEMO.csv\")\n",
    "# df_pdde = pd.read_csv(\"../../LPOINT_BIG_COMP_02_PDDE.csv\")\n",
    "# df_cop_u = pd.read_csv(\"../../LPOINT_BIG_COMP_03_COP_U.csv\")\n",
    "# df_pd_clac = pd.read_csv(\"../../LPOINT_BIG_COMP_04_PD_CLAC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choongs load\n",
    "# df_cust = pd.read_csv(\"../../LPOINT_BIG_COMP/LPOINT_BIG_COMP_01_DEMO.csv\")\n",
    "# df_pdde = pd.read_csv(\"../../LPOINT_BIG_COMP/LPOINT_BIG_COMP_02_PDDE.csv\")\n",
    "# df_cop_u = pd.read_csv(\"../../LPOINT_BIG_COMP/LPOINT_BIG_COMP_03_COP_U.csv\")\n",
    "# df_pd_clac = pd.read_csv(\"../../LPOINT_BIG_COMP/LPOINT_BIG_COMP_04_PD_CLAC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Domain Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN을 통해 이상치 제거\n",
    "def delete_outlier_DBSCAN(df_pdde, df_pd_clac):\n",
    "    df_pdde_pd_clac = df_pdde.merge(df_pd_clac, how='left', on='pd_c')\n",
    "    df_pt = pd.pivot_table(data=df_pdde_pd_clac,\n",
    "               values='buy_am',\n",
    "               index='cust',\n",
    "               columns='clac_hlv_nm',\n",
    "               aggfunc='sum',\n",
    "               fill_value=0)\n",
    "\n",
    "    df_pt.reset_index(inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_pt.iloc[:,1:])\n",
    "    df_spt = pd.DataFrame(scaler.transform(df_pt.iloc[:,1:]), index=df_pt[\"cust\"], columns=df_pt.columns[1:])\n",
    "    df_spt_2 =  df_spt.reset_index()\n",
    "\n",
    "    dbscan = DBSCAN(eps = 0.1, min_samples = 30, metric = \"euclidean\")\n",
    "    dbscan_labels = dbscan.fit_predict(df_spt_2.iloc[:, 1:])\n",
    "    df_spt_2['outlier'] = dbscan_labels\n",
    "\n",
    "    df_spt_not_outlier_cust = df_spt_2[df_spt_2['outlier']==0]['cust']\n",
    "    \n",
    "    return df_spt_not_outlier_cust\n",
    "\n",
    "\n",
    "\n",
    "# 누락 데이터 삭제\n",
    "def check_on_off(df_main, df, key=\"cust\", col_nm=\"chnl_dv\"):\n",
    "    df_new = pd.DataFrame(df.groupby(key)[col_nm].apply(lambda x:list(set(x))))\n",
    "    return df_main.merge(df_new, how=\"left\", on=key).dropna(subset=[\"chnl_dv\"])\n",
    "\n",
    "\n",
    "\n",
    "# on/off 분류\n",
    "def split_on_off(df, col_nm=\"chnl_dv\"):\n",
    "    df[col_nm] = df[col_nm].apply(lambda x: x[0] if len(x)==1 else 0)\n",
    "    df_off = df.loc[df[col_nm]==1] ##off\n",
    "    df_on = df.loc[df[col_nm]==2] ##on\n",
    "    df_onf = df.loc[df[col_nm]==0] ##onf\n",
    "\n",
    "    df_not_off = pd.concat([df_on, df_onf], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    return df_off, df_not_off #off, not_off\n",
    "\n",
    "def classification_buy_am(x, std_points):\n",
    "    if x <= std_points[0]:\n",
    "        return \"D\"\n",
    "    elif std_points[0] < x <= std_points[1]:\n",
    "        return \"C\"\n",
    "    elif std_points[1] < x <= std_points[2]:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"A\"\n",
    "\n",
    "def split_buy_amount_by_4(df_main, df_sub, key='cust', col_nm='buy_am'):\n",
    "    df_new = df_sub.groupby([key], as_index=False)[col_nm].sum()\n",
    "    df_new2 = df_main.merge(df_new, on='cust', how='left')\n",
    "    df_new2[\"am_class\"] = df_new2[col_nm].apply(classification_buy_am, std_points=np.quantile(df_new2[col_nm], [.25, .5, .75]))\n",
    "    \n",
    "\n",
    "    df_A = df_new2[df_new2['am_class']=='A']\n",
    "    df_B = df_new2[df_new2['am_class']=='B']\n",
    "    df_C = df_new2[df_new2['am_class']=='C']\n",
    "    df_D = df_new2[df_new2['am_class']=='D']\n",
    "    \n",
    "    return df_A, df_B, df_C, df_D\n",
    "    \n",
    "\n",
    "def domain_clustering_ver2(df_main, df_sub, df_sub2):\n",
    "\n",
    "    not_outlier_cust = delete_outlier_DBSCAN(df_sub, df_sub2)\n",
    "\n",
    "    df_main = df_main.loc[df_main['cust'].isin(not_outlier_cust.values.tolist())]\n",
    "\n",
    "    df = check_on_off(df_main, df_sub)\n",
    "\n",
    "    df_off, df_not_off= split_on_off(df)\n",
    "\n",
    "    \n",
    "    df_off_A, df_off_B, df_off_C, df_off_D  = split_buy_amount_by_4(df_off, df_sub)\n",
    "    df_not_off_A, df_not_off_B, df_not_off_C, df_not_off_D  = split_buy_amount_by_4(df_not_off, df_sub)\n",
    "\n",
    "    df_off_A['cluster'] = 0\n",
    "    df_off_B['cluster'] = 1\n",
    "    df_off_C['cluster'] = 2\n",
    "    df_off_D['cluster'] = 3\n",
    "    df_not_off_A['cluster'] = 4\n",
    "    df_not_off_B['cluster'] = 5\n",
    "    df_not_off_C['cluster'] = 6\n",
    "    df_not_off_D['cluster'] = 7\n",
    "\n",
    "    df_off_A_label = df_off_A[['cust', 'cluster']]\n",
    "    df_off_B_label = df_off_B[['cust', 'cluster']]\n",
    "    df_off_C_label = df_off_C[['cust', 'cluster']]\n",
    "    df_off_D_label = df_off_D[['cust', 'cluster']]\n",
    "    df_not_off_A_label = df_not_off_A[['cust', 'cluster']]\n",
    "    df_not_off_B_label = df_not_off_B[['cust', 'cluster']]\n",
    "    df_not_off_C_label = df_not_off_C[['cust', 'cluster']]\n",
    "    df_not_off_D_label = df_not_off_D[['cust', 'cluster']]\n",
    "    \n",
    "\n",
    "        \n",
    "    return df_off_A_label, df_off_B_label, df_off_C_label, df_off_D_label, df_not_off_A_label, df_not_off_B_label, df_not_off_C_label, df_not_off_D_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off_A_label, df_off_B_label, df_off_C_label, df_off_D_label, df_not_off_A_label, df_not_off_B_label, df_not_off_C_label, df_not_off_D_label = domain_clustering_ver2(df_cust, df_pdde, df_pd_clac) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.K means Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 아래 함수에서 각각의 데이터프레임 넣어서 각각에 대한 군집 뽑아내서 붙이려고 하나로 합치고 시작했슴당\n",
    "\n",
    "df_list = [df_off_A_label, df_off_B_label, df_off_C_label, df_off_D_label, df_not_off_A_label, df_not_off_B_label, df_not_off_C_label, df_not_off_D_label]\n",
    "df_dom_clustered = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.merge(df_pdde, df_pd_clac, how='left', on='pd_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(df1, df2):\n",
    "    return pd.merge(df1, df2, how='left', on='cust')\n",
    "\n",
    "\n",
    "# def pivoting(df_main, df):\n",
    "def pivoting(df_main, df):\n",
    "    columns_default = list(df_main['clac_hlv_nm'].unique())\n",
    "    df_res = pd.DataFrame(columns=columns_default)\n",
    "    df_pt = pd.pivot_table(data=df,\n",
    "                           values='buy_am',\n",
    "                           index='cust',\n",
    "                           columns='clac_hlv_nm',\n",
    "                           aggfunc='sum',\n",
    "                           fill_value=0)\n",
    "    df_res = pd.concat([df_res, df_pt], ignore_index=False, axis=0)\n",
    "    df_res.fillna(0, inplace=True)\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler.fit(df_res)\n",
    "    # df_spt = pd.DataFrame(scaler.transform(df_res), index=df_pt.indeㄴx, columns=df_res.columns)\n",
    "    # return df_spt\n",
    "    return df_res\n",
    "\n",
    "\n",
    "### 추가한 부분 ###\n",
    "def fit_scaler(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "    return scaler\n",
    "\n",
    "def transform_scaler(df, scaler):\n",
    "    return pd.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)\n",
    "###################\n",
    "\n",
    "def get_inertia(df, k):\n",
    "    Kmeans = KMeans(n_clusters=k, random_state=200)\n",
    "    Kmeans.fit(df)\n",
    "    return Kmeans.inertia_\n",
    "\n",
    "def get_clusters_k(df):\n",
    "    k_range = range(2, 20)\n",
    "    k_result = None\n",
    "\n",
    "    for k in k_range:\n",
    "        minus = get_inertia(df, k) - get_inertia(df, k + 1)\n",
    "        if k == 2:\n",
    "            minus_before = minus\n",
    "            minus_rate_max = 0\n",
    "        else:\n",
    "            minus_rate = minus_before - minus\n",
    "            if minus_rate > minus_rate_max:\n",
    "                k_result = k\n",
    "                minus_rate_max = minus_rate\n",
    "            minus_before = minus\n",
    "\n",
    "    return k_result\n",
    "\n",
    "\n",
    "def clustering(df_main, df_dom_clustered):   ### 여기서 돌릴 때, 초기 데이터이면 fit만 하고, column명들 저장. 초기 데이터 아니면 다음으로 넘어가서 transform만\n",
    "    df = merging(df_main, df_dom_clustered)\n",
    "    \n",
    "    ### 전체 스케일링 먼저 ###\n",
    "    df_total_pt = pivoting(df, df)\n",
    "    mms_scaler = fit_scaler(df_total_pt)\n",
    "    ###\n",
    "    \n",
    "    df_result = pd.DataFrame()\n",
    "    db_clustered_k = df_dom_clustered['cluster'].nunique()\n",
    "    for i in range(db_clustered_k):\n",
    "        df_ = df[df['cluster']==i]\n",
    "        df_pt = pivoting(df_main, df_)\n",
    "        \n",
    "        ### 추가 라인 ###\n",
    "        k = get_clusters_k(transform_scaler(df_pt, mms_scaler))\n",
    "        ###\n",
    "        \n",
    "        # k = get_clusters_k(df_pt)\n",
    "        Kmeans_ = KMeans(n_clusters=k, random_state=200)\n",
    "        Kmeans_.fit(df_pt)\n",
    "        cluster = Kmeans_.predict(df_pt)\n",
    "        df_pt['buy_am_cluster'] = cluster\n",
    "        df_result = pd.concat([df_result, df_pt])\n",
    "        # break\n",
    "    df_result.fillna(0, inplace=True)\n",
    "    # df_result.reset_index(drop=False)\n",
    "    df_result.reset_index(drop=False, inplace=True)\n",
    "    df_result.rename({\"index\":\"cust\"}, axis=1, inplace=True)\n",
    "    df_result = df_result.merge(df_dom_clustered, how=\"left\", on=\"cust\")\n",
    "    df_clustered_final = df_result.loc[:, ['cust', 'buy_am_cluster', 'cluster']]\n",
    "    \n",
    "    return df_clustered_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total_pt = pivoting(df_main)\n",
    "# mms_scaler = fit_scaler(df_total_pt)\n",
    "# transform_scaler(df_total_pt, mms_scaler)\n",
    "df_osy = clustering(df_main, df_dom_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust</th>\n",
       "      <th>buy_am_cluster</th>\n",
       "      <th>cluster</th>\n",
       "      <th>comb_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M000261625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M000350564</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M000508243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M001694463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M001697472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25038</th>\n",
       "      <td>M996376807</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25039</th>\n",
       "      <td>M997082506</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25040</th>\n",
       "      <td>M998129365</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25041</th>\n",
       "      <td>M998600186</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25042</th>\n",
       "      <td>M999105944</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25043 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cust  buy_am_cluster  cluster  comb_cluster\n",
       "0      M000261625               0        0             0\n",
       "1      M000350564               4        0             1\n",
       "2      M000508243               0        0             0\n",
       "3      M001694463               0        0             0\n",
       "4      M001697472               0        0             0\n",
       "...           ...             ...      ...           ...\n",
       "25038  M996376807               1        7            26\n",
       "25039  M997082506               2        7            28\n",
       "25040  M998129365               0        7            27\n",
       "25041  M998600186               0        7            27\n",
       "25042  M999105944               1        7            26\n",
       "\n",
       "[25043 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_cluster = df_osy.iloc[:,1].astype(str)+df_osy.iloc[:,2].astype(str)\n",
    "df_osy[\"comb_cluster\"] = comb_cluster.apply(lambda x: comb_cluster.unique().tolist().index(x))\n",
    "df_osy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Recommending Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수화\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "##2만여명 고객 품목별 구매금액 Scale\n",
    "\n",
    "def pivot_table_for_recommed(df_pd, df_pdc):\n",
    "    df_norm = df_pd.loc[df_pdde[\"cust\"].isin(delete_outlier_DBSCAN(df_pd, df_pdc).values.tolist())]\n",
    "    df_pdde_pd_clac = df_norm.merge(df_pdc, how='left', on='pd_c')\n",
    "    df_pt = pd.pivot_table(data=df_pdde_pd_clac,\n",
    "                values='buy_am',\n",
    "                index='cust',\n",
    "                columns='clac_hlv_nm',\n",
    "                aggfunc='sum',\n",
    "                fill_value=0)\n",
    "\n",
    "    df_pt.reset_index(inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_pt.iloc[:,1:])\n",
    "    df_spt = pd.DataFrame(scaler.transform(df_pt.iloc[:,1:]), index=df_pt[\"cust\"], columns=df_pt.columns[1:])\n",
    "    df_spt_2 =  df_spt.reset_index()\n",
    "    return df_spt_2\n",
    "\n",
    "\n",
    "##클러스터 별로 나누는 함수 정의 필요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##가까운 3명 뽑기 위한 dist map생성 df<-클러스터별로 나누는 함수가 들어간다.\n",
    "def make_dist_map_pick_near_3(df):\n",
    "    dist_map = cdist(df.iloc[:,1:], df.iloc[:,1:], metric='cosine')\n",
    "    dist_map_df = pd.DataFrame(dist_map, index=df[\"cust\"], columns=df[\"cust\"])\n",
    "\n",
    "    temp_dict = dict()\n",
    "    for i in dist_map_df.index.tolist():\n",
    "        temp_dict[i] = dist_map_df.loc[i,:].sort_values()[1:4].index.tolist()\n",
    "\n",
    "    df_cust_near = pd.DataFrame(temp_dict)\n",
    "    df_cust_near_result = df_cust_near.T\n",
    "\n",
    "    return df_cust_near_result\n",
    "\n",
    "\n",
    "def code_to_name(df :pd.DataFrame, col_name :str, df_pdc :pd.DataFrame):\n",
    "    df_result = copy.deepcopy(df)\n",
    "    matching_series = df_pdc.set_index(\"pd_c\")\n",
    "    df_result[col_name] = df[col_name].apply(lambda x: matching_series.loc[x, \"pd_nm\"])\n",
    "    return df_result\n",
    "\n",
    "\n",
    "\n",
    "def make_cust_recommend_item(df, df_pd, df_pdc):\n",
    "    \n",
    "    recommend_dict = {}\n",
    "    except_list = []\n",
    "\n",
    "    for cust_num in tqdm(df.index):\n",
    "    # sample은 이웃의 모든 구매 목록 리스트\n",
    "        sample = df_pd.loc[df_pd[\"cust\"].isin(df.loc[cust_num,:].tolist())]['pd_c'].value_counts()\n",
    "\n",
    "    # sample_result는 이웃의 모든 구매 목록 리스트와 Target(M000261625)의 구매 목록 리스트를 비교해 Target이 구매하지 않은 품목을 찾음\n",
    "        sample_result = set(sample.index)-set(df_pd.loc[df_pdde['cust']==cust_num]['pd_c'].values)\n",
    "\n",
    "    # df_smp\n",
    "        df_smp = pd.DataFrame()\n",
    "        df_smp[\"neighbor_list\"] = list(sample_result)\n",
    "        df_smp[\"neighbor_buy_am\"] = list(map(lambda x: sample[x] ,list(sample_result)))\n",
    "        df_smp_nm = code_to_name(df_smp.sort_values(\"neighbor_buy_am\", ascending=False), \"neighbor_list\", df_pdc)\n",
    "    \n",
    "        try:\n",
    "            # sample_dff = pd.DataFrame(df_smp_nm, \"neighbor_list\", df_pd_clac)[0:3]['neighbor_list'].T\n",
    "            sample_dff = df_smp_nm.iloc[:3,0].values.tolist()\n",
    "            recommend_dict[cust_num] = sample_dff\n",
    "        except:\n",
    "            except_list.append((cust_num,len(df_smp_nm.iloc[:,0].values)))\n",
    "            continue\n",
    "\n",
    "    final_result_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in recommend_dict.items() ]))\n",
    "    final_df = final_result_df.T\n",
    "    # sample_dff.columns = [0,1,2]\n",
    "    # sample_dff.index = [cust_num]\n",
    "    # final_result_df = pd.concat([final_result_df,sample_dff], axis=0, ignore_index=True)\n",
    "\n",
    "    return final_df, except_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>clac_hlv_nm</th>\n",
       "      <th>cust</th>\n",
       "      <th>가구</th>\n",
       "      <th>건강식품</th>\n",
       "      <th>건강용품</th>\n",
       "      <th>건해산물</th>\n",
       "      <th>...</th>\n",
       "      <th>테넌트/음식점</th>\n",
       "      <th>패션잡화</th>\n",
       "      <th>퍼스널케어</th>\n",
       "      <th>헬스/피트니스</th>\n",
       "      <th>화장품/뷰티케어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M000034966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M000201112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M000225114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046184</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M000261625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162458</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.136348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M000350564</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.045439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25038</th>\n",
       "      <td>M999599111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25039</th>\n",
       "      <td>M999673157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.023606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25040</th>\n",
       "      <td>M999770689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029356</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034202</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25041</th>\n",
       "      <td>M999849895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029968</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25042</th>\n",
       "      <td>M999962961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040122</td>\n",
       "      <td>0.066175</td>\n",
       "      <td>0.027351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25043 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "clac_hlv_nm        cust        가구      건강식품      건강용품      건해산물  ...  \\\n",
       "0            M000034966  0.000000  0.000000  0.000000  0.005936  ...   \n",
       "1            M000201112  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "2            M000225114  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "3            M000261625  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "4            M000350564  0.002474  0.080532  0.000000  0.000000  ...   \n",
       "...                 ...       ...       ...       ...       ...  ...   \n",
       "25038        M999599111  0.000000  0.004852  0.000000  0.008511  ...   \n",
       "25039        M999673157  0.000000  0.000000  0.000000  0.000000  ...   \n",
       "25040        M999770689  0.000000  0.029356  0.007665  0.000000  ...   \n",
       "25041        M999849895  0.000000  0.000000  0.001319  0.000000  ...   \n",
       "25042        M999962961  0.000000  0.004039  0.000000  0.007223  ...   \n",
       "\n",
       "clac_hlv_nm   테넌트/음식점      패션잡화     퍼스널케어  헬스/피트니스  화장품/뷰티케어  \n",
       "0            0.000000  0.000000  0.000000      0.0  0.000000  \n",
       "1            0.000000  0.000000  0.000000      0.0  0.000000  \n",
       "2            0.046184  0.004713  0.000000      0.0  0.018674  \n",
       "3            0.162458  0.000392  0.136348      0.0  0.166908  \n",
       "4            0.004929  0.045439  0.000000      0.0  0.032260  \n",
       "...               ...       ...       ...      ...       ...  \n",
       "25038        0.000000  0.000000  0.000000      0.0  0.000000  \n",
       "25039        0.003204  0.023606  0.000000      0.0  0.006706  \n",
       "25040        0.034202  0.000402  0.000000      0.0  0.000000  \n",
       "25041        0.029968  0.000590  0.000000      0.0  0.000000  \n",
       "25042        0.040122  0.066175  0.027351      0.0  0.027808  \n",
       "\n",
       "[25043 rows x 59 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal_dist = pivot_table_for_recommed(df_pdde, df_pd_clac)\n",
    "df_normal_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal_dist = pivot_table_for_recommed(df_pdde, df_pd_clac)\n",
    "\n",
    "cluster_recommend_dict = dict()\n",
    "cluster_exception = dict()\n",
    "\n",
    "for clust_no in df_osy[\"comb_cluster\"].unique():\n",
    "    ## -- 클러스터 1개 당 df 정의\n",
    "    clust_list = df_osy.loc[df_osy[\"comb_cluster\"]==clust_no][\"cust\"].values.tolist()\n",
    "    df_similar = df_normal_dist.loc[df_normal_dist[\"cust\"].isin(clust_list)]\n",
    "    cluster_recommend_dict[clust_no], cluster_exception[clust_no] = make_cust_recommend_item(make_dist_map_pick_near_3(df_similar),df_pdde, df_pd_clac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules about neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연관 규칙 도출 Flow 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import *\n",
    "\n",
    "def make_association_rule(df, order=\"rct_no\", prod_code=\"pd_c\", min_support=.003, min_confidence=.1):\n",
    "    # 장바구니 별 상품 리스트\n",
    "    product_list_per_order = df.groupby(order)[prod_code].apply(list)\n",
    "    \n",
    "    # 연관 규칙을 위한 encoding\n",
    "    encoder = TransactionEncoder()\n",
    "    one_hot_df = encoder.fit_transform(product_list_per_order)\n",
    "    one_hot_df = pd.DataFrame(one_hot_df, columns=encoder.columns_)\n",
    "    \n",
    "    # 연관 규칙 도출\n",
    "    frequent_item_df = apriori(one_hot_df, min_support=min_support)\n",
    "    result = association_rules(frequent_item_df, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    \n",
    "    # 정리후 리턴\n",
    "    result = result[[\"antecedents\", \"consequents\", \"support\", \"confidence\"]].sort_values(by=\"confidence\", ascending=False).reset_index(drop=True)\n",
    "    result[\"antecedents\"] = result[\"antecedents\"].apply(lambda x: df.loc[df[prod_code]==one_hot_df.columns[list(x)[0]]][prod_code].values[0])\n",
    "    result[\"consequents\"] = result[\"consequents\"].apply(lambda x: df.loc[df[prod_code]==one_hot_df.columns[list(x)[0]]][prod_code].values[0])\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "42a636b4ae40231869e16fcf30ae97d54d85a7f895f1f4f5db0d943359100379"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
