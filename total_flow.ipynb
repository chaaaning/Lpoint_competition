{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"font.family\"] = \"Malgun Gothic\"\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "plt.rcParams[\"figure.figsize\"] = (16,9)\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "pd.set_option(\"display.max_columns\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # choongs load\n",
    "# df_cust = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_01_DEMO.csv\")\n",
    "# df_pdde = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_02_PDDE.csv\")\n",
    "# df_cop_u = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_03_COP_U.csv\")\n",
    "# df_pd_clac = pd.read_csv(\"../LPOINT_BIG_COMP/LPOINT_BIG_COMP_04_PD_CLAC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## osy load\n",
    "# df_cust = pd.read_csv(\"../../LPOINT_BIG_COMP_01_DEMO.csv\")\n",
    "# df_pdde = pd.read_csv(\"../../LPOINT_BIG_COMP_02_PDDE.csv\")\n",
    "# df_cop_u = pd.read_csv(\"../../LPOINT_BIG_COMP_03_COP_U.csv\")\n",
    "# df_pd_clac = pd.read_csv(\"../../LPOINT_BIG_COMP_04_PD_CLAC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunjc\\AppData\\Local\\Temp\\ipykernel_32196\\1028514978.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_pdde = pd.read_csv(\"./LPOINT_BIG_COMP/LPOINT_BIG_COMP_02_PDDE.csv\")\n"
     ]
    }
   ],
   "source": [
    "# rnch load\n",
    "df_cust = pd.read_csv(\"./LPOINT_BIG_COMP/LPOINT_BIG_COMP_01_DEMO.csv\")\n",
    "df_pdde = pd.read_csv(\"./LPOINT_BIG_COMP/LPOINT_BIG_COMP_02_PDDE.csv\")\n",
    "df_cop_u = pd.read_csv(\"./LPOINT_BIG_COMP/LPOINT_BIG_COMP_03_COP_U.csv\")\n",
    "df_pd_clac = pd.read_csv(\"./LPOINT_BIG_COMP/LPOINT_BIG_COMP_04_PD_CLAC.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def make_ts_column(df, date=\"de_dt\", hour=\"de_hr\", drop=False):\n",
    "    \n",
    "    if df[date].dtypes==\"str\" and df[hour].dtypes==\"int64\":\n",
    "        df[\"de_dthr\"]=pd.to_datetime(df[date]+\":\"+df[hour].apply(str), format=\"%Y-%m-%d:%H\")\n",
    "    elif df[date].dtypes==\"<M8[ns]\" and df[hour].dtypes==\"int64\":\n",
    "        df[\"de_dthr\"]=pd.to_datetime(df[date].apply(lambda x: datetime.strftime(x, format=\"%Y-%m-%d\"))+\":\"+df[hour].apply(str),format=\"%Y-%m-%d:%H\")\n",
    "    elif df[date].dtypes==\"int64\" and df[hour].dtypes==\"int64\":\n",
    "        df[\"de_dthr\"]=pd.to_datetime(df[date].apply(str)+\":\"+df[hour].apply(str),format=\"%Y%m%d:%H\")\n",
    "    else:\n",
    "        # assert df[date].dtypes!=\"str\" or df[date].dtypes!=\"<M8[ns]\", \"date must be 'str' or '<M8[ns]' type\"\n",
    "        # assert df[hour].dtypes!=\"int\", \"hour must be 'int' type\"\n",
    "        raise TypeError(\"Check args type -> date must be 'str' or '<M8[ns]' type. hour must be 'int' type.\") \n",
    "    \n",
    "    if drop:\n",
    "        return df.drop([\"de_dt\", \"de_hr\"], axis=1)\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust</th>\n",
       "      <th>rct_no</th>\n",
       "      <th>chnl_dv</th>\n",
       "      <th>cop_c</th>\n",
       "      <th>br_c</th>\n",
       "      <th>...</th>\n",
       "      <th>de_dt</th>\n",
       "      <th>de_hr</th>\n",
       "      <th>buy_am</th>\n",
       "      <th>buy_ct</th>\n",
       "      <th>de_dthr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M430112881</td>\n",
       "      <td>A01000001113</td>\n",
       "      <td>1</td>\n",
       "      <td>A01</td>\n",
       "      <td>A010039</td>\n",
       "      <td>...</td>\n",
       "      <td>20210101</td>\n",
       "      <td>10</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M646853852</td>\n",
       "      <td>A01000002265</td>\n",
       "      <td>1</td>\n",
       "      <td>A01</td>\n",
       "      <td>A010025</td>\n",
       "      <td>...</td>\n",
       "      <td>20210101</td>\n",
       "      <td>10</td>\n",
       "      <td>79700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M430112881</td>\n",
       "      <td>A01000003148</td>\n",
       "      <td>1</td>\n",
       "      <td>A01</td>\n",
       "      <td>A010039</td>\n",
       "      <td>...</td>\n",
       "      <td>20210101</td>\n",
       "      <td>10</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M430112881</td>\n",
       "      <td>A01000004946</td>\n",
       "      <td>1</td>\n",
       "      <td>A01</td>\n",
       "      <td>A010039</td>\n",
       "      <td>...</td>\n",
       "      <td>20210101</td>\n",
       "      <td>10</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M430112881</td>\n",
       "      <td>A01000005297</td>\n",
       "      <td>1</td>\n",
       "      <td>A01</td>\n",
       "      <td>A010039</td>\n",
       "      <td>...</td>\n",
       "      <td>20210101</td>\n",
       "      <td>10</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 10:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cust        rct_no  chnl_dv cop_c     br_c  ...     de_dt  de_hr  \\\n",
       "0  M430112881  A01000001113        1   A01  A010039  ...  20210101     10   \n",
       "1  M646853852  A01000002265        1   A01  A010025  ...  20210101     10   \n",
       "2  M430112881  A01000003148        1   A01  A010039  ...  20210101     10   \n",
       "4  M430112881  A01000004946        1   A01  A010039  ...  20210101     10   \n",
       "5  M430112881  A01000005297        1   A01  A010039  ...  20210101     10   \n",
       "\n",
       "    buy_am  buy_ct             de_dthr  \n",
       "0  15000.0       1 2021-01-01 10:00:00  \n",
       "1  79700.0       1 2021-01-01 10:00:00  \n",
       "2  19000.0       1 2021-01-01 10:00:00  \n",
       "4  19000.0       1 2021-01-01 10:00:00  \n",
       "5   9900.0       1 2021-01-01 10:00:00  \n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dthr = make_ts_column(df_pdde)\n",
    "df_dthr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dthr_dd = df_dthr.drop_duplicates(subset=[\"cust\",\"rct_no\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가로 제외할 고객 cust\n",
    "cust_0110 = set(df_dthr_dd.loc[df_dthr_dd[\"de_dthr\"]<=pd.to_datetime(\"2021-11-01\")].drop_duplicates(\"cust\")[\"cust\"].values.tolist())\n",
    "cust_1112 = set(df_dthr_dd.loc[df_dthr_dd[\"de_dthr\"]>pd.to_datetime(\"2021-11-01\")].drop_duplicates(\"cust\")[\"cust\"].values.tolist())\n",
    "cust_only_1112 = list(cust_1112 - cust_0110)    # 첫 번째에서 제외\n",
    "cust_only_0110 = list(cust_0110 - cust_1112)    # 평가에서 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test\n",
    "df_train = df_dthr_dd.loc[df_dthr_dd[\"de_dthr\"]<pd.to_datetime(\"2021-11-01\")]\n",
    "df_test = df_dthr_dd.loc[df_dthr_dd[\"de_dthr\"]>=pd.to_datetime(\"2021-11-01\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Domain Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBSCAN을 통해 이상치 제거\n",
    "def delete_outlier_DBSCAN(df_pdde, df_pd_clac):\n",
    "    df_pdde_pd_clac = df_pdde.merge(df_pd_clac, how='left', on='pd_c')\n",
    "    df_pt = pd.pivot_table(data=df_pdde_pd_clac,\n",
    "               values='buy_am',\n",
    "               index='cust',\n",
    "               columns='clac_hlv_nm',\n",
    "               aggfunc='sum',\n",
    "               fill_value=0)\n",
    "\n",
    "    df_pt.reset_index(inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_pt.iloc[:,1:])\n",
    "    df_spt = pd.DataFrame(scaler.transform(df_pt.iloc[:,1:]), index=df_pt[\"cust\"], columns=df_pt.columns[1:])\n",
    "    df_spt_2 =  df_spt.reset_index()\n",
    "\n",
    "    dbscan = DBSCAN(eps = 0.1, min_samples = 30, metric = \"euclidean\")\n",
    "    dbscan_labels = dbscan.fit_predict(df_spt_2.iloc[:, 1:])\n",
    "    df_spt_2['outlier'] = dbscan_labels\n",
    "\n",
    "    df_spt_not_outlier_cust = df_spt_2[df_spt_2['outlier']==0]['cust']\n",
    "    \n",
    "    return df_spt_not_outlier_cust\n",
    "\n",
    "\n",
    "\n",
    "# 누락 데이터 삭제\n",
    "def check_on_off(df_main, df, key=\"cust\", col_nm=\"chnl_dv\"):\n",
    "    df_new = pd.DataFrame(df.groupby(key)[col_nm].apply(lambda x:list(set(x))))\n",
    "    return df_main.merge(df_new, how=\"left\", on=key).dropna(subset=[\"chnl_dv\"])\n",
    "\n",
    "\n",
    "\n",
    "# on/off 분류\n",
    "def split_on_off(df, col_nm=\"chnl_dv\"):\n",
    "    df[col_nm] = df[col_nm].apply(lambda x: x[0] if len(x)==1 else 0)\n",
    "    df_off = df.loc[df[col_nm]==1] ##off\n",
    "    df_on = df.loc[df[col_nm]==2] ##on\n",
    "    df_onf = df.loc[df[col_nm]==0] ##onf\n",
    "\n",
    "    df_not_off = pd.concat([df_on, df_onf], axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    return df_off, df_not_off #off, not_off\n",
    "\n",
    "def classification_buy_am(x, std_points):\n",
    "    if x <= std_points[0]:\n",
    "        return \"D\"\n",
    "    elif std_points[0] < x <= std_points[1]:\n",
    "        return \"C\"\n",
    "    elif std_points[1] < x <= std_points[2]:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"A\"\n",
    "\n",
    "def split_buy_amount_by_4(df_main, df_sub, key='cust', col_nm='buy_am'):\n",
    "    df_new = df_sub.groupby([key], as_index=False)[col_nm].sum()\n",
    "    df_new2 = df_main.merge(df_new, on='cust', how='left')\n",
    "    df_new2[\"am_class\"] = df_new2[col_nm].apply(classification_buy_am, std_points=np.quantile(df_new2[col_nm], [.25, .5, .75]))\n",
    "    \n",
    "\n",
    "    df_A = df_new2[df_new2['am_class']=='A']\n",
    "    df_B = df_new2[df_new2['am_class']=='B']\n",
    "    df_C = df_new2[df_new2['am_class']=='C']\n",
    "    df_D = df_new2[df_new2['am_class']=='D']\n",
    "    \n",
    "    return df_A, df_B, df_C, df_D\n",
    "    \n",
    "\n",
    "def domain_clustering_ver2(df_main, df_sub, df_sub2):\n",
    "\n",
    "    not_outlier_cust = delete_outlier_DBSCAN(df_sub, df_sub2)\n",
    "\n",
    "    df_main = df_main.loc[df_main['cust'].isin(not_outlier_cust.values.tolist())]\n",
    "\n",
    "    df = check_on_off(df_main, df_sub)\n",
    "\n",
    "    df_off, df_not_off= split_on_off(df)\n",
    "\n",
    "    \n",
    "    df_off_A, df_off_B, df_off_C, df_off_D  = split_buy_amount_by_4(df_off, df_sub)\n",
    "    df_not_off_A, df_not_off_B, df_not_off_C, df_not_off_D  = split_buy_amount_by_4(df_not_off, df_sub)\n",
    "\n",
    "    df_off_A['cluster'] = 0\n",
    "    df_off_B['cluster'] = 1\n",
    "    df_off_C['cluster'] = 2\n",
    "    df_off_D['cluster'] = 3\n",
    "    df_not_off_A['cluster'] = 4\n",
    "    df_not_off_B['cluster'] = 5\n",
    "    df_not_off_C['cluster'] = 6\n",
    "    df_not_off_D['cluster'] = 7\n",
    "\n",
    "    df_off_A_label = df_off_A[['cust', 'cluster']]\n",
    "    df_off_B_label = df_off_B[['cust', 'cluster']]\n",
    "    df_off_C_label = df_off_C[['cust', 'cluster']]\n",
    "    df_off_D_label = df_off_D[['cust', 'cluster']]\n",
    "    df_not_off_A_label = df_not_off_A[['cust', 'cluster']]\n",
    "    df_not_off_B_label = df_not_off_B[['cust', 'cluster']]\n",
    "    df_not_off_C_label = df_not_off_C[['cust', 'cluster']]\n",
    "    df_not_off_D_label = df_not_off_D[['cust', 'cluster']]\n",
    "    \n",
    "\n",
    "        \n",
    "    return df_off_A_label, df_off_B_label, df_off_C_label, df_off_D_label, df_not_off_A_label, df_not_off_B_label, df_not_off_C_label, df_not_off_D_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off_A_label, df_off_B_label, df_off_C_label, df_off_D_label, df_not_off_A_label, df_not_off_B_label, df_not_off_C_label, df_not_off_D_label = domain_clustering_ver2(df_cust, df_pdde, df_pd_clac) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.K means Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 아래 함수에서 각각의 데이터프레임 넣어서 각각에 대한 군집 뽑아내서 붙이려고 하나로 합치고 시작했슴당\n",
    "\n",
    "df_list = [df_off_A_label, df_off_B_label, df_off_C_label, df_off_D_label, df_not_off_A_label, df_not_off_B_label, df_not_off_C_label, df_not_off_D_label]\n",
    "df_dom_clustered = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.merge(df_pdde, df_pd_clac, how='left', on='pd_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging(df1, df2):\n",
    "    return pd.merge(df1, df2, how='left', on='cust')\n",
    "\n",
    "\n",
    "# def pivoting(df_main, df):\n",
    "def pivoting(df_main, df):\n",
    "    columns_default = list(df_main['clac_hlv_nm'].unique())\n",
    "    df_res = pd.DataFrame(columns=columns_default)\n",
    "    df_pt = pd.pivot_table(data=df,\n",
    "                           values='buy_am',\n",
    "                           index='cust',\n",
    "                           columns='clac_hlv_nm',\n",
    "                           aggfunc='sum',\n",
    "                           fill_value=0)\n",
    "    df_res = pd.concat([df_res, df_pt], ignore_index=False, axis=0)\n",
    "    df_res.fillna(0, inplace=True)\n",
    "\n",
    "    # scaler = MinMaxScaler()\n",
    "    # scaler.fit(df_res)\n",
    "    # df_spt = pd.DataFrame(scaler.transform(df_res), index=df_pt.indeㄴx, columns=df_res.columns)\n",
    "    # return df_spt\n",
    "    return df_res\n",
    "\n",
    "\n",
    "### 추가한 부분 ###\n",
    "def fit_scaler(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "    return scaler\n",
    "\n",
    "def transform_scaler(df, scaler):\n",
    "    return pd.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)\n",
    "###################\n",
    "\n",
    "def get_inertia(df, k):\n",
    "    Kmeans = KMeans(n_clusters=k, random_state=200)\n",
    "    Kmeans.fit(df)\n",
    "    return Kmeans.inertia_\n",
    "\n",
    "def get_clusters_k(df):\n",
    "    k_range = range(2, 20)\n",
    "    k_result = None\n",
    "\n",
    "    for k in k_range:\n",
    "        minus = get_inertia(df, k) - get_inertia(df, k + 1)\n",
    "        if k == 2:\n",
    "            minus_before = minus\n",
    "            minus_rate_max = 0\n",
    "        else:\n",
    "            minus_rate = minus_before - minus\n",
    "            if minus_rate > minus_rate_max:\n",
    "                k_result = k\n",
    "                minus_rate_max = minus_rate\n",
    "            minus_before = minus\n",
    "\n",
    "    return k_result\n",
    "\n",
    "\n",
    "def clustering(df_main, df_dom_clustered):   ### 여기서 돌릴 때, 초기 데이터이면 fit만 하고, column명들 저장. 초기 데이터 아니면 다음으로 넘어가서 transform만\n",
    "    df = merging(df_main, df_dom_clustered)\n",
    "    \n",
    "    ### 전체 스케일링 먼저 ###\n",
    "    df_total_pt = pivoting(df, df)\n",
    "    mms_scaler = fit_scaler(df_total_pt)\n",
    "    ###\n",
    "    \n",
    "    df_result = pd.DataFrame()\n",
    "    db_clustered_k = df_dom_clustered['cluster'].nunique()\n",
    "    for i in range(db_clustered_k):\n",
    "        df_ = df[df['cluster']==i]\n",
    "        df_pt = pivoting(df_main, df_)\n",
    "        \n",
    "        ### 추가 라인 ###\n",
    "        k = get_clusters_k(transform_scaler(df_pt, mms_scaler))\n",
    "        ###\n",
    "        \n",
    "        # k = get_clusters_k(df_pt)\n",
    "        Kmeans_ = KMeans(n_clusters=k, random_state=200)\n",
    "        Kmeans_.fit(df_pt)\n",
    "        cluster = Kmeans_.predict(df_pt)\n",
    "        df_pt['buy_am_cluster'] = cluster\n",
    "        df_result = pd.concat([df_result, df_pt])\n",
    "        # break\n",
    "    df_result.fillna(0, inplace=True)\n",
    "    # df_result.reset_index(drop=False)\n",
    "    df_result.reset_index(drop=False, inplace=True)\n",
    "    df_result.rename({\"index\":\"cust\"}, axis=1, inplace=True)\n",
    "    df_result = df_result.merge(df_dom_clustered, how=\"left\", on=\"cust\")\n",
    "    df_clustered_final = df_result.loc[:, ['cust', 'buy_am_cluster', 'cluster']]\n",
    "    \n",
    "    return df_clustered_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total_pt = pivoting(df_main)\n",
    "# mms_scaler = fit_scaler(df_total_pt)\n",
    "# transform_scaler(df_total_pt, mms_scaler)\n",
    "df_osy = clustering(df_main, df_dom_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust</th>\n",
       "      <th>buy_am_cluster</th>\n",
       "      <th>cluster</th>\n",
       "      <th>comb_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M000261625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M000350564</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M000508243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M001694463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M001697472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25038</th>\n",
       "      <td>M996376807</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25039</th>\n",
       "      <td>M997082506</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25040</th>\n",
       "      <td>M998129365</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25041</th>\n",
       "      <td>M998600186</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25042</th>\n",
       "      <td>M999105944</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25043 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cust  buy_am_cluster  cluster  comb_cluster\n",
       "0      M000261625               0        0             0\n",
       "1      M000350564               4        0             1\n",
       "2      M000508243               0        0             0\n",
       "3      M001694463               0        0             0\n",
       "4      M001697472               0        0             0\n",
       "...           ...             ...      ...           ...\n",
       "25038  M996376807               1        7            26\n",
       "25039  M997082506               2        7            28\n",
       "25040  M998129365               0        7            27\n",
       "25041  M998600186               0        7            27\n",
       "25042  M999105944               1        7            26\n",
       "\n",
       "[25043 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_cluster = df_osy.iloc[:,1].astype(str)+df_osy.iloc[:,2].astype(str)\n",
    "df_osy[\"comb_cluster\"] = comb_cluster.apply(lambda x: comb_cluster.unique().tolist().index(x))\n",
    "df_osy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Recommending Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수화\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "##2만여명 고객 품목별 구매금액 Scale\n",
    "def pivot_table_for_recommend(df_pd, df_pdc):\n",
    "    df_norm = df_pd.loc[df_pdde[\"cust\"].isin(delete_outlier_DBSCAN(df_pd, df_pdc).values.tolist())]\n",
    "    df_pdde_pd_clac = df_norm.merge(df_pdc, how='left', on='pd_c')\n",
    "    df_pt = pd.pivot_table(data=df_pdde_pd_clac,\n",
    "                values='buy_am',\n",
    "                index='cust',\n",
    "                columns='clac_hlv_nm',\n",
    "                aggfunc='sum',\n",
    "                fill_value=0)\n",
    "\n",
    "    df_pt.reset_index(inplace=True)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_pt.iloc[:,1:])\n",
    "    df_spt = pd.DataFrame(scaler.transform(df_pt.iloc[:,1:]), index=df_pt[\"cust\"], columns=df_pt.columns[1:])\n",
    "    df_spt_2 =  df_spt.reset_index()\n",
    "    return df_spt_2\n",
    "\n",
    "\n",
    "##클러스터 별로 나누는 함수 정의 필요.\n",
    "\n",
    "\n",
    "##가까운 3명 뽑기 위한 dist map생성 df<-클러스터별로 나누는 함수가 들어간다.\n",
    "def make_dist_map_pick_near_3(df):\n",
    "    dist_map = cdist(df.iloc[:,1:], df.iloc[:,1:], metric='cosine')\n",
    "    dist_map_df = pd.DataFrame(dist_map, index=df[\"cust\"], columns=df[\"cust\"])\n",
    "\n",
    "    temp_dict = dict()\n",
    "    for i in dist_map_df.index.tolist():\n",
    "        temp_dict[i] = dist_map_df.loc[i,:].sort_values()[1:4].index.tolist()\n",
    "\n",
    "    df_cust_near = pd.DataFrame(temp_dict)\n",
    "    df_cust_near_result = df_cust_near.T\n",
    "\n",
    "    return df_cust_near_result\n",
    "\n",
    "def code_to_name(df :pd.DataFrame, col_name :str, df_pdc :pd.DataFrame):\n",
    "    df_result = copy.deepcopy(df)\n",
    "    matching_series = df_pdc.set_index(\"pd_c\")\n",
    "    df_result[col_name] = df[col_name].apply(lambda x: matching_series.loc[x, \"pd_nm\"])\n",
    "    return df_result\n",
    "\n",
    "def make_cust_recommend_item(df, df_pd, df_pdc):\n",
    "    \n",
    "    recommend_dict = {}\n",
    "    except_list = []\n",
    "\n",
    "    for cust_num in tqdm(df.index):\n",
    "    # sample은 이웃의 모든 구매 목록 리스트\n",
    "        sample = df_pd.loc[df_pd[\"cust\"].isin(df.loc[cust_num,:].tolist())]['pd_c'].value_counts()\n",
    "\n",
    "    # sample_result는 이웃의 모든 구매 목록 리스트와 Target(M000261625)의 구매 목록 리스트를 비교해 Target이 구매하지 않은 품목을 찾음\n",
    "        sample_result = set(sample.index)-set(df_pd.loc[df_pdde['cust']==cust_num]['pd_c'].values)\n",
    "\n",
    "    # df_smp\n",
    "        df_smp = pd.DataFrame()\n",
    "        df_smp[\"neighbor_list\"] = list(sample_result)\n",
    "        df_smp[\"neighbor_buy_am\"] = list(map(lambda x: sample[x] ,list(sample_result)))\n",
    "        df_smp_nm = code_to_name(df_smp.sort_values(\"neighbor_buy_am\", ascending=False), \"neighbor_list\", df_pdc)\n",
    "    \n",
    "        try:\n",
    "            # sample_dff = pd.DataFrame(df_smp_nm, \"neighbor_list\", df_pd_clac)[0:3]['neighbor_list'].T\n",
    "            sample_dff = df_smp_nm.iloc[:3,0].values.tolist()\n",
    "            recommend_dict[cust_num] = sample_dff\n",
    "        except:\n",
    "            except_list.append((cust_num,len(df_smp_nm.iloc[:,0].values)))\n",
    "            continue\n",
    "\n",
    "    final_result_df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in recommend_dict.items() ]))\n",
    "    final_df = final_result_df.T\n",
    "    # sample_dff.columns = [0,1,2]\n",
    "    # sample_dff.index = [cust_num]\n",
    "    # final_result_df = pd.concat([final_result_df,sample_dff], axis=0, ignore_index=True)\n",
    "\n",
    "    return final_df, except_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcd8a9f166e46d0b718808124c24782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88d4382ab9d48f084bbffbb63b76478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f13e13d3c044aba3129ee971552a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3aea4379614ad784d627dbe95bc2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124b2b5cfeca4c7ead7ea48f75af3043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e940b398984617b51f8777015edb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842388d8454f40c983876a34b5ba1810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2605 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6d8734c73e42bfbe7662aab769c8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2e517507bd4f20a804455073ae4aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/556 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cf0c3e884c4c6ea085922191fa0b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2867 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8523bf226e4c6c9fa60477645d7f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c464a057c58843eb88c1cb199daa8a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39160d51907c4ca58ad45a61701c64e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3787 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fca8fa7cb03432a8bd5825a4c6e0a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0095a4af7749b2bfbdc870bcb578fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70a83fd6c9e4b86af2699b9e6e5a6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676225d4a4b8402095c6874d09591b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366d1240abbc4960b5e01ee7f5a8da68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1789 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dfd354d3634415889465ba4f39e2872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4bd247c7204dc3abfd51d1b9cc1f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93097a3e233742ab92010f6e4e2a45af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e1c3086cac4269bb6e562f43f1fbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fcb7589757490ca98ae153b5df8c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/141 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454447292693448d9494921e15d91b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1ff000b38946bfb6c430264df6dc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1373 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd90aa58d0245fc97ec38f716211c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1758470751d4a08a6fe906b05b50470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/698 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f03afcb30a4d8883531d06374339c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1813 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07bc1d894574230a1e078d4937d76e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabfb4e0f687467ca067487fbb21c380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "df_normal_dist = pivot_table_for_recommend(df_pdde, df_pd_clac)\n",
    "\n",
    "cluster_recommend_dict = dict()\n",
    "cluster_exception = dict()\n",
    "\n",
    "for clust_no in tqdm(df_osy[\"comb_cluster\"].unique()):\n",
    "    ## -- 클러스터 1개 당 df 정의\n",
    "    clust_list = df_osy.loc[df_osy[\"comb_cluster\"]==clust_no][\"cust\"].values.tolist()\n",
    "    df_similar = df_normal_dist.loc[df_normal_dist[\"cust\"].isin(clust_list)]\n",
    "    cluster_recommend_dict[clust_no], cluster_exception[clust_no] = make_cust_recommend_item(make_dist_map_pick_near_3(df_similar),df_pdde, df_pd_clac)\n",
    "    \n",
    "c_rd = copy.deepcopy(cluster_recommend_dict)\n",
    "c_ex = copy.deepcopy(cluster_exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M000261625</th>\n",
       "      <td>기타남성의류세트</td>\n",
       "      <td>남성스포츠티셔츠</td>\n",
       "      <td>기타건과일</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M000508243</th>\n",
       "      <td>기타남성의류세트</td>\n",
       "      <td>성인침구세트</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M001694463</th>\n",
       "      <td>즉석무침반찬</td>\n",
       "      <td>젤리</td>\n",
       "      <td>양식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M001697472</th>\n",
       "      <td>국산담배</td>\n",
       "      <td>수입맥주</td>\n",
       "      <td>국물용기라면</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M001729158</th>\n",
       "      <td>종량제봉투</td>\n",
       "      <td>생활잡화균일가</td>\n",
       "      <td>일반스낵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M998346579</th>\n",
       "      <td>여성티셔츠/탑</td>\n",
       "      <td>디저트</td>\n",
       "      <td>젤리</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999213998</th>\n",
       "      <td>비빔봉지라면</td>\n",
       "      <td>방울토마토</td>\n",
       "      <td>냉동떡볶이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999227380</th>\n",
       "      <td>기타아웃도어/레저용품</td>\n",
       "      <td>기타파티/팬시용품</td>\n",
       "      <td>남성티셔츠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999340261</th>\n",
       "      <td>기타컴퓨터액세서리</td>\n",
       "      <td>키보드</td>\n",
       "      <td>국산담배</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M999673157</th>\n",
       "      <td>수입담배</td>\n",
       "      <td>쿠키</td>\n",
       "      <td>파이</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3543 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0          1       2\n",
       "M000261625     기타남성의류세트   남성스포츠티셔츠   기타건과일\n",
       "M000508243     기타남성의류세트     성인침구세트      한식\n",
       "M001694463       즉석무침반찬         젤리      양식\n",
       "M001697472         국산담배       수입맥주  국물용기라면\n",
       "M001729158        종량제봉투    생활잡화균일가    일반스낵\n",
       "...                 ...        ...     ...\n",
       "M998346579      여성티셔츠/탑        디저트      젤리\n",
       "M999213998       비빔봉지라면      방울토마토   냉동떡볶이\n",
       "M999227380  기타아웃도어/레저용품  기타파티/팬시용품   남성티셔츠\n",
       "M999340261    기타컴퓨터액세서리        키보드    국산담배\n",
       "M999673157         수입담배         쿠키      파이\n",
       "\n",
       "[3543 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_rd[0]\n",
    "# pd.DataFrame(c_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules about neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연관 규칙 도출 Flow 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import *\n",
    "\n",
    "def make_association_rule(df, order=\"rct_no\", prod_code=\"pd_c\", min_support=.003, min_confidence=.1):\n",
    "    # 장바구니 별 상품 리스트\n",
    "    product_list_per_order = df.groupby(order)[prod_code].apply(list)\n",
    "    \n",
    "    # 연관 규칙을 위한 encoding\n",
    "    encoder = TransactionEncoder()\n",
    "    one_hot_df = encoder.fit_transform(product_list_per_order)\n",
    "    one_hot_df = pd.DataFrame(one_hot_df, columns=encoder.columns_)\n",
    "    \n",
    "    # 연관 규칙 도출\n",
    "    frequent_item_df = apriori(one_hot_df, min_support=min_support)\n",
    "    result = association_rules(frequent_item_df, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    \n",
    "    # 정리후 리턴\n",
    "    result = result[[\"antecedents\", \"consequents\", \"support\", \"confidence\"]].sort_values(by=\"confidence\", ascending=False).reset_index(drop=True)\n",
    "    result[\"antecedents\"] = result[\"antecedents\"].apply(lambda x: df.loc[df[prod_code]==one_hot_df.columns[list(x)[0]]][prod_code].values[0])\n",
    "    result[\"consequents\"] = result[\"consequents\"].apply(lambda x: df.loc[df[prod_code]==one_hot_df.columns[list(x)[0]]][prod_code].values[0])\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('main')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "5418eef80854e52bdd31b62ac8e168a96471c21ff09caab6ca68827813545a18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
